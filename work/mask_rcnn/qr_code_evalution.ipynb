{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da84adc-b8fa-4bef-b282-9570a810241b",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f8e53e-be11-4a80-b2c1-81f9fd6fc8bf",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7829e5e1-3895-438f-9bbd-82096a4fe7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install fiftyone\n",
    "!pip install pyzbar\n",
    "!pip install opencv-python\n",
    "!pip install seaborn\n",
    "!pip install openpyxl\n",
    "!pip install qreader\n",
    "!pip install pyboof\n",
    "!pip install dbr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df07d94f-cd39-437c-81a8-91956b8da9c2",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c04cd5a-4265-41b2-aed6-6783a5fe0e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data.catalog import Metadata\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiftyone as fo\n",
    "from PIL import Image, ImageOps\n",
    "from PIL.ExifTags import TAGS\n",
    "from pathlib import Path\n",
    "from pyzbar.pyzbar import decode\n",
    "from pyzbar.pyzbar import ZBarSymbol\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd33d2b-5c5d-4ae2-b5bf-a01167751ccc",
   "metadata": {},
   "source": [
    "### Specify Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048e453-a4ee-4055-89ff-cf49b8ab4458",
   "metadata": {},
   "source": [
    "There are several output folders from training multiple models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2437332e-f435-4de1-a050-0676852694d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(thing_classes=['leaf', 'qr', 'red-square'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set this to today's date\n",
    "today = \"2024-03-15\"\n",
    "\n",
    "# modify output folder suffix if needed\n",
    "suffix = \"kfold_train\"\n",
    "\n",
    "# name of output folder\n",
    "output_folder_name = today + \"_\" + suffix\n",
    "\n",
    "data_path = '/home/jovyan/work/data/2024-03-14_leaves'\n",
    "output_folder = f'/home/jovyan/work/mask_rcnn/{output_folder_name}'\n",
    "\n",
    "k=5\n",
    "\n",
    "# set up metadata\n",
    "leaf_metadata = Metadata()\n",
    "leaf_metadata.set(thing_classes = ['leaf', 'qr', 'red-square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22158348-7b28-44ff-b6d9-fd39df9e4c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import fiftyone as fo\n",
    "import cv2\n",
    "import subprocess\n",
    "from qreader import QReader\n",
    "\n",
    "def append_qr_to_filename(filename):\n",
    "    root, ext = os.path.splitext(filename)\n",
    "    return f\"{root}_qr{ext}\"\n",
    "\n",
    "\n",
    "# Assuming leaf_predictor is defined elsewhere and dataset is an iterable of samples\n",
    "datasets = {}\n",
    "qreader = QReader()\n",
    "\n",
    "for fold in range(0, 5):\n",
    "    \n",
    "    base_path = f\"{output_folder}/fold_{fold}/\"\n",
    "\n",
    "    leaf_cfg = get_cfg()\n",
    "    leaf_cfg.MODEL.DEVICE='cpu'\n",
    "    leaf_cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    leaf_cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "    leaf_cfg.MODEL.WEIGHTS = base_path + \"model_final.pth\" # path to trained weights\n",
    "    leaf_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set a custom testing threshold\n",
    "\n",
    "    leaf_predictor = DefaultPredictor(leaf_cfg)\n",
    "    \n",
    "    print(f'Loading fold {fold} into fiftyone dataset...')\n",
    "    \n",
    "    datasets[f'fold_{fold}'] = fo.Dataset.from_dir(\n",
    "        data_path=f\"{data_path}\",\n",
    "        labels_path=f\"{output_folder}/test_{fold}.json\",\n",
    "        dataset_type=fo.types.COCODetectionDataset, \n",
    "        name=f\"{today}_fold_{fold}\",\n",
    "        label_types=\"segmentations\",\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    print(f'Performing inference for fold {fold}...')\n",
    "    \n",
    "\n",
    "    with fo.ProgressBar() as pb:\n",
    "        for sample in pb(datasets[f'fold_{fold}']):\n",
    "            image = Image.open(sample.filepath)\n",
    "            image = ImageOps.exif_transpose(image)  # Ensure correct orientation\n",
    "            image_arr = np.array(image)\n",
    "            h, w, _ = image_arr.shape\n",
    "\n",
    "            outputs = leaf_predictor(image_arr)\n",
    "            pred_boxes = outputs['instances'].pred_boxes.tensor.numpy()\n",
    "            class_labels = outputs['instances'].pred_classes.numpy()\n",
    "\n",
    "            qr_indices = []\n",
    "            leaf_indices = []\n",
    "        \n",
    "            # get indices of leaves and qr codes\n",
    "            for i, label in enumerate(class_labels):\n",
    "                 if label == 1: # qr\n",
    "                    qr_indices.append(i)\n",
    "\n",
    "            # if qr code was detected, decode\n",
    "            crop_img = None\n",
    "            qr_result_decoded = None\n",
    "\n",
    "            if len(qr_indices):\n",
    "\n",
    "                # get first qr code (assumes there is only 1 code per image)\n",
    "                bbox = pred_boxes[qr_indices[0]]\n",
    "\n",
    "                # (x0, y0, x1, y1)  Get bounds of QR code +-500px\n",
    "                x0 = round(bbox[0].item()-500)\n",
    "                y0 = round(bbox[1].item()-500)\n",
    "                x1 = round(bbox[2].item()+500)\n",
    "                y1 = round(bbox[3].item()+500)\n",
    "\n",
    "                # crop to bounding box for QR decoding\n",
    "                crop_img = image_arr[ y0:y1, x0:x1]\n",
    "\n",
    "                scale_percent = 50 # percent of original size\n",
    "                width = int(crop_img.shape[1] * scale_percent / 100)\n",
    "                height = int(crop_img.shape[0] * scale_percent / 100)\n",
    "                dim = (width, height)\n",
    "\n",
    "                # resize image\n",
    "                crop_img_resized = cv2.resize(crop_img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "                save_path = 'cropped_qr_codes/' + append_qr_to_filename(os.path.basename(sample.filepath))\n",
    "\n",
    "                image_to_save = Image.fromarray(crop_img_resized)\n",
    "                image_to_save.save(save_path)\n",
    "                \n",
    "                \n",
    "                cmd = subprocess.run(\n",
    "                    [\"python\", \"decode_qr.py\"],\n",
    "                    capture_output=True,\n",
    "                    check=False,\n",
    "                    text=True\n",
    "                )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dab4a13b-24d6-46f5-8e8b-9447966f3bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_images': 172, 'pyzbar_success': 82, 'pyzbar_success_percent': 47.674418604651166, 'opencv_success': 15, 'opencv_success_percent': 8.720930232558139, 'qreader_success': 127, 'qreader_success_percent': 73.83720930232558, 'dbr_success': 144, 'dbr_success_percent': 83.72093023255815}\n",
      "Percentage of images with successful decoding: 73.84%\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Directory containing images\n",
    "image_folder = 'cropped_qr_codes'\n",
    "\n",
    "# Run the script\n",
    "!python decode_qr_codes.py {image_folder}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa1dff-7e80-4e78-95ad-8619f061b5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd1fcb-d101-4a9d-9dc4-4edcb71f9326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
